[TOC]
----


# 1. MySQL的在文件中是如何存储的？
- 数据是存在页中的，一页的大小是 16kb, 一个表由很多的页组成，这些页组成了 B+树。 每页之间数据结构是一个双向链表。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821143256977-1332888425.png)

# 2. 二叉树、B树、B+树
二叉树具有以下性质：左子树的键值小于根的键值，右子树
的键值大于根的键值。二叉树的查询效率就低了。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821154010052-779184076.png)

平衡二叉树（AVL树）在符合二叉查找树的条件下，还满足任何节点的两个子树的高度最大差为1。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821154037213-1789401676.png)


平衡多路查找树（B-Tree），系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来。InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位，默认16K。InnoDB每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小16KB。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821154057316-1843035106.png)


缺点：每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。

B+Tree相对于B-Tree有几点不同：
非叶子节点只存储键值信息。
所有叶子节点之间都有一个链指针。
数据记录都存放在叶子节点中

在数据库中，B+Tree的高度一般都在2~4层。mysql的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821154117840-1597722525.png)


数据库索引采用B+树的主要原因是：B树在提高了IO性能的同时并没有解决元素遍历的我效率低下的问题，正是为了解决这个问题，B+树应用而生。
B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。



# 3. B+ 树能存放多少条数据？为啥inno DB单表记录推荐2000万行

- 总记录数为 = **根节点指针数\*单个叶子节点记录行数 **。
- 比如聚集索引，主键ID为bigInt 长度为8 字节，innoDB 源码设置为6字节，一条记录就是14字节。一页能放 16*1024÷14 = 1170
- 假如每条数据大小为1K, 一页能存放16k/1k = 16.
- 高度为3的能放 1170\*1170\* 16 = 219002400，大概2200万左右。主键索引最多查询3次，非主键索引要查6(3+3)次。
- 如果是 非聚集索引，叶子结点存放的是聚集索引(主键Id)，则能存放的数量更大。


# 4. Mysql 日志文件介绍

（1）通过数据库锁的机制，保障事务的**隔离性**；
（2）通过 Redo Log（重做日志）来，保障事务的**持久性**；
（3）通过 Undo Log （撤销日志）来，保障事务的**原子性**；
（4）通过 Undo Log （撤销日志）来，保障事务的**一致性**；

- 慢查询日志（slow query log）:记录慢查询的日志文件
- 查询日志（general log）:记录所有对数据库请求的信息
- 重做日志（redo log）: 记录更新的值，事务提交后生效。固定大写、循环写。以物理方式记录了对数据库页的更改。
- 回滚日志（undo log）: 记录原来的值，事务回滚时，用于恢复原来的值。主要用于事务的回滚与MVCC。
- 二进制日志（binlog）:用于数据库备份、主从复制，从库利用主库上的binlog进行重播，实现主从同步。
    - 通过sync_binlog控制二进制日志同步磁盘信息：为0时，mysql不做控制，依赖Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘；为n时，代表n次事务提交之后进行强制刷盘。
- 错误日志（errorlog）:
- 中继日志（relay log）: 主从复制中，暂存主库Binlog日志的

![](https://img2024.cnblogs.com/blog/1694759/202405/1694759-20240511180514254-1344438541.png)




# 5. MySQL中Myisam与Innodb的区别

- 索引上的区别：
    + InnoDB主键索引是聚簇索引，MyISAM索引是非聚簇索引。
    + InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
    + MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。
    + InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。
    + InnoDB支持MVCC、外键，Myisam不支持,支持全文索引。
- 表/行锁差异: InnoDB支持事物、支持行级锁(基于索引来完成行锁)，Myisam支持表级锁,不支持事物。
- 表主键：MyISAM允许没有主键与索引。InnoDB如果没设置主键或者非空索引,就会自动生成一个6字节的主键(用户不可见)
- 行数统计count：没有where的count()使用MyISAM要比InnoDB快得多。因为MyISAM内置了一个计数器，count()时它直接从计数器中读，而InnoDB必须扫描全表。

# 6. Innodb引擎四大特点

- **插入缓冲（insert buffer)**：先将数据插入或更新 写到Buffer Pool 缓冲池,然后再按一定频率一起写到硬盘，目的 减少IO带来的损耗。
- **二次写(double write)**：位于系统表空间的存储区域，用来缓存InnoDB的数据页从innodb buffer pool中flush之后并写入到数据文件之前。
- **自适应哈希索引(ahi)**：某二级索引被频繁访问、减少B+树查询次数(2-4次)，系统自动建立哈希索引，加快查询速度。
- **预读(read ahead)** : 如果一个w磁盘区(extent)中的被顺序读取的page超过或者等于该参数变量时，Innodb将会异步的将下一个extent读取到buffer pool中



# 7. 什么是多版本并发控制(MVCC)
保存数据的历史版本，通过对数据行的多个版本管理来实现数据库的并发控制,通过MVCC可以解决以下几个问题:
- 1.**并发读写**之间阻塞的问题，提升事务并发处理能力。
- 2.降低死锁的概率。MVCC采用了**乐观锁**的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。
- 3.解决一致性读的问题。一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。

### MVCC的实现原理
- MVCC 多版本并发控制,对于innodb存储引擎，每条行记录都包含两个隐藏列 timestamp 时间戳、db_trx_id事务Id、db_roll_ptr回滚指针。
  -- timestamp 时间戳，用于个确定版本的时间顺序
  -- trx_id 当前修改的事务id
  -- roll_pointer 每次对某条聚集索引记录进行改动时，都会把旧版本写入undo日志中。这个隐藏列就相当于一个指针，通过它找到该记录修改前的信息。
  -- 通过 ReadView+ UndoLog 实现的，UndoLog保存了历史快照，所有的版本都会被db_roll_ptr属性形成**版本链** ，版本链的头节点就是当前记录最新的值，每个版本中还包含生成该版本时对应的事务ID(db_trx_id)。ReadView 规则帮助判断当前版本的数据是否可见。

- **快照读**：不加锁的简单 Select 都属于快照读。
- **当前读**：就是读的是最新数据,而不是历史的数据，加锁的 SELECT，或者对数据进行增删改都会进行当前读。

- Read View 保存了当前事务开启时所有活跃的事务列表。可以理解为: Read View 保存了不应该让这个事务看到的其他事务 ID 列表。
    - m_ids 系统当前正在活跃的事务ID集合。
    - min_trx_id  活跃的事务中最小的事务 ID。
    - creator_trx_id，创建这个 ReadView 的事务ID。
    - max_trx_id ,生成ReadView时系统中应该分配给下一个事务的id值。

- Read View 查询数据：
    - 获取事务自己的版本号，即 事务ID
    - 获取 Read View
    - 查询得到的数据，然后 Read View 中的事务版本号进行比较。
    - 如果不符合 ReadView 规则， 那么就需要 UndoLog 中历史快照；
    - 最后返回符合规则的数据

- Read View 规则：
  -- 如果被访问版本的 db_trx_id 值等于ReadView中的 creator_trx_id 值，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
  -- 如果被访问版本的 db_trx_id 值小于ReadView中的 min_trx_id 值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。
  -- 如果被访问版本的 db_trx_id 值大于或等于ReadView中的 max_trx_id 值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。
  -- 如果被访问版本的 db_trx_id 值在ReadView的 min_trx_id 和 max_trx_id 之间， db_trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。
  -- 如果某个版本的数据对当前事务不可见，就顺着版本链找到上一个版本的数据，继续按照上边的步骤依次判断可见性，直到版本链中最早的版本。如果最早的版本也不可见，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。

![MVCC数据可见性算法判断流程图](https://segmentfault.com/img/remote/1460000041553225)

![版本链结构](https://segmentfault.com/img/remote/1460000041553224)

### ReadView 中**读已提交**与**可重复读**隔离级别的区别

- **读已提交**  每次读取数据前都生成一个 ReadView。
- **可重复读**  只在第一次读取数据时生成一个 ReadView。

# 8. 可重复读什么场景下还会产生幻读
可重复读（RepeatableRead）通过多版本并发控制（MVCC）机制在很大程度上避免了不可重复读的问题，但在特定场景下，幻读仍然可能发生。幻读通常指的是在一个事务范围内，两次执行相同的范围查询时，第二次查询返回了第一次查询时不存在的新行，主要原因是**其他事务中插入的**。产生幻读的典型场景包括：

- 事务开始前，普通select是不加锁（select..for update）, 即MVCC机制的快照读。因为没有相关临建锁（next-key lock），其他事物在此期间插入数据。然后在执行当前读的时候，就会发现两次查询的记录条目不一样了，这也就产生了幻读。
- 如果事务上来就加锁执行（select..for update），此种会进行加锁，影响其他事物的并行对写。

从MySQL 5.5版本开始，InnoDB引入了可重复读隔离级别下的幻读预防机制，即所谓的Next-Key Locks，这在一定程度上减少了幻读的发生。Next-Key Lock实际上是一个行锁加上前驱间隙锁的组合，它能阻止在已锁定的区间内插入新的记录，从而在很多情况下避免了幻读。然而，这种机制并不能完全消除所有幻读的可能性，特别是在**不涉及唯一索引的范围查询**中，或者当新插入的记录恰好填补了两个现有记录之间的间隙时，幻读仍然可能出现。

# 9. Innodb的事务与日志的实现方式
- 隔离级别：读未提交(RU)、读已提交(RC)、可重复读(RR)、Serializable串行化，mysql默认可重复读RR，Oracle默认采用RC。mysql通过MVCC(多版本控制)和 Next-key lock(间隙锁)解决了幻读。
- MVCC是解决读写并行的幻读，而next-key lock 间隙锁 是解决写写并行的幻读。
- 间隙锁（Next-Key锁）:防止幻读,当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；
  对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。在Read Committed及RU隔离级别下，不会使用间隙锁。
- RR隔离级别**没有完全解决幻读问题**,同一个事务里面通过当前读(select for update之类、update、insert、delete)或者多个事务先更新然后快照读的形式来获取数据，就会产生幻读。
- RR快照读只会读取当前事务下数据的“历史态”，但当更新(dml、ddl）时，事务会去查看“当前态”某些数据行，验证数据的可执行性（如主键冲突、唯一性约束冲突等等）。一但有“当前态”的行数据被更新，这个行就会和当前”历史态“数据合并成新的”历史态“，此后该事务的快照读均是读取的新”历史态“快照。
- 当前读：对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式。在执行这几个操作时会读取最新的版本号记录，写操作后把版本号改为了当前事务的版本号，所以即使是别的事务提交的数据也可以查询到。
  假设要update一条记录，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据。也正是因为这样所以才导致幻读。

- 幻读：指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。

- **如何解决幻读？**
    - 在快照读情况下,mysql通过mvcc来避免幻读。
    - 在当前读情况下通过X锁或Next-key来避免其他事物修改;
        - 使用串行化隔离级别
        - (update、delete)当where条件作为主键时,通过对主键索引加record locks来处理幻读。
        - (update、delete)当where条件为非主键索引时，通过next-key锁处理。next-key是record locks(索引加锁/行锁) 和 gap locks(间隙锁，每次锁住的不光是需要使用的数据，还会锁住这些数据附近的数据)的结合。

- MVCC 和 Next-Key Locks 能有效减轻幻读问题，但无法在所有情况下完全解决幻读。在某些特定情况下，如涉及范围查询，仍然可能发生幻读。
  比如： 假设有两个事务，事务1和事务2。事务1首先开启事务并查询某些数据，此时只有两行记录。在T3时刻，事务2插入一条数据并立即提交。在T4时刻，事务1再次查询数据时，仍然只能看到T2时刻的数据，这是符合可重复读的。然而，在T5时刻，事务1尝试更新一条不存在的数据，却意外地执行成功了。在T6时刻，事务1再次查询数据时，却发现多了一条记录，这就是幻读的现象。

|事务隔离级别|脏读|不可重复读|幻读|
|:---:|:---:|:---:|:---:|
|读未提交RU|是|是|是|
|读已提交RC|否|是|是|
|可重复读RR|否|否|是|
|串行化|否|否|否|

- RC级别没有间隙锁，通过where条件过滤后，不符合条件的记录的行锁会释放掉。RC的并发性能高于RR。RC允许不可重复读和幻读的。

* Record Lock（记录锁）：锁住某一行记录
* Gap Lock（间隙锁）：锁住一段**左开右开** 的区间.(10,20)
* Next-key Lock（临键锁）：锁住一段**左开右闭** 的区间。等于 Gap Lock间隙锁+Record Lock记录锁。(10,20]

![间隙锁与临键锁加锁分析](https://www.cnblogs.com/a747895159/articles/18066182)


# 15. 聚集索引与非聚集索引

- 聚集索引： 数据行的物理顺序与列值（一般是主键的那一列）的逻辑顺序相同，一个表中只能拥有一个聚集索引,一般指主键。
- 非聚集索引：除聚集索引外其他都是的，包括普通索引，唯一索引，全文索引。叶子节点并不包含行记录的全部数据.
- 使用非聚集索引查询，而查询列中包含了其他该索引没有覆盖的列，那么他还要进行第二次的查询，查询节点上对应的数据行的数据。

# 16. Mysql 索引失效
- 1、查询时索引列不能为null值，因为索引是有序的，建索引时无法确定位置。
- 2、查询时 采用is Null,只能全表扫描。
- 3、数据库数据量较少时，mysql判断全表查询快时将不使用索引。
- 4、like查询以%开头，索引列类型隐士转换、列参与函数运算、使用or查询，联合索引非最左
- 5、数据分布不均匀、使用不等号条件


# 17. Innodb引擎为何 double write files 双写缓冲文件？

- MySQL中一页数据是16kb，操作系统一个页是 4kb，所以刷到磁盘，要写4个文件系统里的页。刷页时并非原子操作,可能会造成「Partial Page Write（部分页写入）」;双写缓冲区由 128 个页（Page）组成，每个页通常是 16KB，因此总大小为 128 * 16KB = 2MB。磁盘上：这部分位于系统表空间的两个连续扩展（extend1 和 extend2），也是 128 个页，同样总计 2MB。
    - 顺序快速：这部分位于磁盘上系统表空间的两个连续扩展（extend1 和 extend2），也是 128 个页，同样总计 2MB。
    - 离散写入：InnoDB会将这些页分别写入到各自对应的数据文件（表空间文件）中，因为每个页可能属于不同的表或索引，因此它们可能分布在不同的位置。

- redo日志是无法修复 部分页写入问题,redo log的内容包括 存储表空间ID、页号、偏移量和需要更新的值,而不是页面的全量记录。
- 通过双写机制，将数据写入到磁盘的两个不同位置，来避免由于磁盘损坏等因素导致数据丢失或不一致的问题。**保证MySQL数据的可靠性和一致性**
- 在系统恢复期间，InnoDB会检查共享表空间中双写缓冲区的副本(double write buffer)，并尝试从中恢复损坏的数据页。如果double write buffer中的数据是完整的，那么InnoDB就会用它数据来更新损坏的页。如果double write buffer中的数据不完整，InnoDB也有可能丢弃buffer内容，重新执行那条redo log以尝试恢复数据。

![](https://img-blog.csdnimg.cn/29cbdc9584af4279a89436948e26b4e4.png)

- 每个InnoDB表都会对应一个或多个**.ibd文件**，其中包含表的数据（包括表的行数据）和索引信息（包括表的主键索引和辅助索引），还包含MVCC相关数据


# 18. 如果脏页没有刷回，数据库宕机了怎么办？修改不就丢失了吗？

- 事务未提交，MySQL宕机，这种情况， Buffer Pool中的数据丢失，并且 redo log buffer中的日志也会丢失，不影响数据。
- 事务提交后，我们可以设置参数***innodb_flush_log_at_trx_commit***来决定redo log 的刷盘策略(设置为 1)：
    - 0 提交事务时，不会将redo log buffer中的数据写入os buffer，而是每秒写入os buffer并刷到磁盘；
    - 1 提交事务时，必须把redo log从内存刷入到磁盘文件中；
    - 2 提交事务时，将redo log写入os buffer中，默认每隔1s将os buffer中的数据刷入磁盘。


# 20. 创建索引的原则？
- 1.较为频繁查询条件的字段；
- 2.字段区分度、离散值较高的；
- 3.索引字段长度不能太长；
- 4.索引的个数不要太多，能复用组合索引尽量复用；
- 5.索引列尽量指定为NOT NULL；

# 21. 索引下推ICP

- Mysql 5.6及之后，index filter和table filter进行分离。index filter在引擎层进行过滤，**减少存储引擎回表查询的数据开销**。
- 就是将原本需要在**Server层**对数据进行过滤的条件下推到了**引擎层**去做，在引擎层过滤更多的数据，这样从引擎层发送到Server层的数据就会显著减少，从而优化性能。
- 在 InnoDB 中.ICP 的目的就是为了减少回表导致的磁盘 I/O，
    - index key ：确定SQL查询在索引中的连续范围(起始范围+结束范围),扫描的索引数据范围。
    - index filter ：根据 index key的索引范围 根据where条件进一步使用索引进行过滤。
    - table filter：where条件中不能使用索引的， 只能 回表查询进行条件过滤。
- 不支持覆盖索引、聚簇索引、子查询条件的下推、存储过程条件、触发器条件的下推

# 22. count 字段区别
- 1.count(可空字段) 扫描全表，读到server层，判断字段可空，拿出该字段所有值，判断每一个值是否为空，不为空则累加
- 2.count(非空字段)与count(主键 id) 扫描全表，读到server层，判断字段不可空，按行累加。
- 3.count(1) 扫描全表，但不取值，server层收到的每一行都是1，判断不可能是null，按值累加。注意：count(1)执行速度比count(主键 id)快的原因：从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。
- 4.count(*)在优化器做了专门优化,返回的行一定不是空。扫描全表，但是不取值，按行累加。


# 23. 慢SQL优化思路

- **慢查询日志记录慢SQL**
- **explain查询分析SQL的执行计划**

    - **type**表示连接类型，查看索引执行情况的一个重要指标。以下性能从好到坏依次：system  > const > eq_ref > ref  > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL
        - system：这种类型要求数据库表中只有一条数据，是const类型的一个特例，一般情况下是不会出现的。
        - const：通过一次索引就能找到数据，一般用于主键或唯一索引作为条件，这类扫描效率极高，，速度非常快。
        - eq_ref：常用于主键或唯一索引扫描，一般指使用主键的关联查询
        - ref : 常用于非主键和唯一索引扫描。
        - ref_or_null：这种连接类型类似于ref，区别在于MySQL会额外搜索包含NULL值的行
        - index_merge：使用了索引合并优化方法，查询使用了两个以上的索引。
        - unique_subquery：类似于eq_ref，条件用了in子查询
        - index_subquery：区别于unique_subquery，用于非唯一索引，可以返回重复值。
        - range：常用于范围查询，比如：between ... and 或 In 等操作
        - index：全索引扫描
        - ALL：全表扫描
    - possible_keys: 可能使用的索引，表示查询可能使用的索引列表。
    - rows: 估计的行数，表示查询扫描的行数估计值。
    - **extra** 该字段包含有关MySQL如何解析查询的其他信息，它一般会出现这几个值
        - Using filesort：表示按文件排序，一般是在指定的排序和索引排序不一致的情况才会出现。一般见于order by语句
        - Using index ：表示是否用了覆盖索引。
        - Using temporary: 表示是否使用了临时表,性能特别差，需要重点优化。一般多见于group by语句，或者union语句。
        - Using where : 表示使用了where条件过滤.
        - Using index condition：MySQL5.6之后新增的索引下推。在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据
- **慢查询SQL注意事项**
    - 隐式转换
    - 最左匹配
    - 深分页问题
    - in元素过多:建议不要超过 200个
    - order by 走文件排序导致的慢查询
    - 索引字段上使用（!=、 not in、is null、is not null），索引可能失效
    - 左右连接，关联的字段编码格式不一样
    - delete + in子查询(大量数据) 可能会扫描全表，不走索引
    - 深分页查询时，利用索引字段子查询方式提升性能.总数量count问题无法解决

```
    SELECT * FROM product WHERE ID > =(select id from product limit 866613, 1) limit 20
```

# 24. Explain执行计划存在的坑

- limit在explain时无效,会忽略limit
- explain预估影响行数的机制,会根据索引前8页与最后一页估算数据平均值,可能会和实际行数差距较大,analyze table 解决.
- 使用索引后、数据扫描过多,可能依然全表扫描,如果SQL查询中涉及相关索引字段的强类型转换,也会全表扫描
- 如果觉得explain不太准，可以使用 show session status like "Handler%"； show profile 这两个命令对SQL进行更准确的分析。

# 28. mysql集群原理及方案

- **异步复制**: 执行事务操作的线程不会等复制 Binlog 的线程。 默认情况下。
    - 在客户端向 MySQL 主库提交事务请求后，主库会先将事务记录到 Binlog，然后提交事务，更新存储引擎的数据，事务提交成功后，返回成功响应给客户端。**同时从库会开启一个专门的复制线程**，接收主库的 Binlog，并将其写入**中继日志**，然后向主库返回复制成功的响应。从库还有一个回放 Binlog 的线程，用于读取中继日志并回放 Binlog 以更新存储引擎的数据。
- **全同步复制**: 须收到所有从库的ack，才会提交事务。性能差，可用性也很差。

- **半同步复制**: 从 5.7 版本开始,事务线程无需等待所有复制成功响应，只需要一部分复制响应返回后，就可以向客户端反馈.
    - 在 master 更新操作写入 Binlog 后，会主动通知 slave，slave 接收到后写入 Relay Log 即可回应。master 只需收到至少一个 ACK 应答，便可提交事务。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821153146830-723209679.png)
![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821153204938-711203546.png)





# 29. 一条查询MySQL的执行过程

- 连接器: 数据库身份验证、权限验证、连接参数配置
- 查询缓存: 检查缓存中是否有,如果有直接返回。
- 解析器和预处理器: 对查询语句进行语法解析(词法分析、语法分析、预处理),转换成内部数据结构。
- 优化器: 会根据查询语句的结构和表的统计信息(数据大小、索引大小)、系统配置缓存与CPU 生成多个查询计划,根据成本估算器挑出最优执行计划。
- 执行器: 根据选定的执行计划,调用存储引擎的API查询数据。
- 存储引擎: 负责实际数据的存储和检索。

![](https://img2024.cnblogs.com/blog/1694759/202402/1694759-20240207113625379-1338904182.png)


# 30. Mysql如何更新一条数据的
- 1. 解析SQL语句：MySQL服务器接收到UPDATE语句后，首先通过解析器（Parser）解析SQL语句，确保语法正确，并构建查询计划。
- 2. 查询优化：分析器后的优化器（Optimizer）根据数据库的统计信息选择最佳的执行计划，例如决定使用哪种索引来访问数据。
- 3. 获取数据：执行器（Executor）根据优化后的计划找到满足WHERE条件的行。如果id是主键，InnoDB存储引擎会使用B+树索引直接定位到行。
- 4. 锁定数据：InnoDB使用行级锁（如Record Locks）来锁定即将更新的行，以避免并发问题。如果需要，还可能使用间隙锁（Gap Locks）或Next-Key Locks 防止幻读。
- 5. 执行更新：
    - 执行器调用存储引擎接口，将新值写入内存中的缓冲池（Buffer Pool）。如果数据页不在内存中，会先从磁盘读取到缓冲池。
    - 当需要更新或者读取某条数据的时候，会把对应的页加载到内存中的 Buffer Pool 缓冲池中（默认为 128m 当然为了提高系统的并发度，你可以把这个值设置大一点）。当更新数据的时候，如果对应的页在 Buffer Pool 中，则直接更新 BP中的数据页即可，如果不在BP中，才会加载磁盘中对应的页到BP中，然后更新，此时BP中的页则跟磁盘中的页不一致，称为脏页。这些脏页是要被刷回磁盘中的。
        - ①. BP不够用了，要给新加载的页腾位置，所以会利用改进的 LRU 算法，将最近最久未使用的脏页刷回磁盘。
        - ②. 后台线程会在MySQL空闲的时候，将脏页刷回到磁盘中
        - ③. redolog写满时
        - ④. 数据库关闭时会将所有脏页刷回到磁盘中。

- 6. 双写缓冲区：修改后的数据页首先写入到双写缓冲区，然后再写入到磁盘上的系统表空间的双写区域。
- 7. Redo Log：修改操作记录在redo log中，并标记为待提交状态。如果配置了innodb_flush_log_at_trx_commit为1或2，redo log会立即写入磁盘。
- 8. 数据页更新：缓冲池中的数据页被更新，并将更新后的页写回磁盘。
- 9. Undolog操作：如果事务是可回滚的，对应的undolog信息也会被记录，以备回滚操作。
- 10. 提交事务：如果事务成功，执行器调用存储引擎接口提交事务，将redo log标记为提交状态。
- 11. Binary Log：事务提交后，binlog（二进制日志）会被写入磁盘，用于复制和恢复。
- 12. 释放锁：事务完成后，锁定的资源被释放。


![](https://img2024.cnblogs.com/blog/1694759/202402/1694759-20240206174634276-1082574582.png)


# 31. Redo log 是循环写的，之前的数据会不会丢失？

Redo Log是InnoDB存储引擎用于实现事务持久性和恢复的关键组件。它是循环写的，意味着当Redo Log的空间用完后，会覆盖旧的记录，但这并不会导致之前的数据丢失，原因如下：

- Checkpoints： InnoDB使用Checkpoints来确保数据的持久性。在每次checkpoint时，InnoDB会将内存中的数据页写入数据文件，并更新系统表空间（System Tablespace）中的redo log位置信息。这样，即使redo log被覆盖，InnoDB也可以通过checkpoint信息知道哪些数据已经安全地写入了数据文件。
- Rollback Segments： 除了Redo Log外，InnoDB还使用Rollback Segments来跟踪事务的回滚信息。这些信息在事务提交后会被清理，因此不会占用Redo Log的长期空间。
- 崩溃恢复： 在系统崩溃或异常关机后，InnoDB会在启动时执行崩溃恢复。它会从最新的checkpoint开始，应用Redo Log中的所有未提交的事务，以确保数据的一致性。已经提交的事务不会丢失，因为它们已经在checkpoint之前写入了数据文件。


# 32.SQL调优方案

- 数据库配置调优: 增加硬件资源、根据场景设置数据库引擎、调整缓冲池(高并发频繁更新时禁用查询缓存)提高读取性能、设置事务隔离级别(高并发场景RC级别)
- 索引优化: 控制索引长度、索引列的分散度、索引的数量、复合索引、索引类型
- 覆盖索引: 减少不需要的字段返回，减少回表查询
- 索引下推: 可以在索引层面进行部分条件的过滤，减少回表操作，提高查询效率。
- 排序优化: 减少不必要的排序，部分排序使索引失效
- 子查询优化: 执行子查询时，MYSQL需要创建临时表，查询完毕后再删除这些临时表。根据情况改用join方式 或 大表场景推荐应用层merge数据。
- SQL语句优化: 分页查询limit场景,越往后越慢(使用上一页索引条件替代：id> xx); 报表类多表关联改成ES或者宽表实现；索引字段失效场景


# 33. MySQL的MRR

MRR多（Multi-Range Read optimization）范围读取优化,**适用于索引覆盖**。是 InnoDB 存储引擎为了提高 **范围查询（如 BETWEEN, IN 等**的性能而引入的一种优化技术。
在没有 MRR 之前，InnoDB 对于范围查询可能会执行大量的随机 I/O 操作，因为每次读取一个记录后，可能需要跳转到磁盘上的另一个位置来读取下一个记录。这种随机 I/O 会严重影响性能，尤其是在机械硬盘上。
MRR 的工作原理是：
- 预读：当执行一个范围查询时，InnoDB 会首先读取所有需要的索引条目，并将它们按照主键顺序排序。
- 顺序读取：然后，InnoDB 会按照主键顺序读取所需的行数据。因为数据在磁盘上是按主键顺序存储的，所以这种读取是顺序的，而不是随机的，从而大大提高了 I/O 效率。

必须是“索引覆盖的”，这意味着查询只需要访问索引，而不需要访问实际的行数据。如果查询需要访问实际的行数据，那么即使用了MRR，性能提升不明显。


# 34. LSM树(Log Structured Merge Trees)原理

- 将对数据的修改增量保存在内存中，达到指定大小限制之后批量把数据flush到磁盘中，磁盘中树定期可以做merge操作，合并成一棵大树，以优化读性能。不过读取的时候稍微麻烦一些，读取时看这些数据在内存中，如果未能命中内存，则需要访问较多的磁盘文件。
- LSM牺牲了部分读性能，提高写性能。适用于写多读少的场景。主要劣势：读写放大（磁盘上实际读写的数据量 / 用户需要的数据量）。
- LSM是当前被用在许多产品的文件结构策略：HBase,TIDB,mangoDb 等。
- LSM树的核心特点是利用顺序写来提高写性能，但因为分层(此处分层是指的分为内存和文件两部分)的设计会稍微降低读性能，但是通过牺牲小部分读性能换来高性能写，使得LSM树成为非常流行的存储结构。

![](https://img2020.cnblogs.com/blog/1694759/202111/1694759-20211119204033094-907558566.png)

![](https://img2020.cnblogs.com/blog/1694759/202111/1694759-20211119205246316-371070524.png)

![](https://img2020.cnblogs.com/blog/1694759/202111/1694759-20211119205331509-1561924404.png)

