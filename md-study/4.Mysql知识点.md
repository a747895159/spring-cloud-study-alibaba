[TOC]

----


# 1. MySQL的在文件中是如何存储的？

- 数据是存在页中的，一页的大小是**16kb**, 一个表由很多的页组成，这些页组成了 B+树。 每页之间数据结构是一个双向链表。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821143256977-1332888425.png)

## 常用注意点

DATETIME 的存储空间为 8 字节；TIMESTAMP 的存储空间为 4 字节.
DATETIME 存储时间与时区无关；TIMESTAMP 存储时间与时区有关.
DATETIME 的日期范围可以到9999年；TIMESTAMP 只能到2038年。
UNION在表链接后筛选掉重复的记录行；UNION ALL，不会合并重复的记录行；
使用 utf8mb4 字符集可以存储emoji表情。
limit start,num  限制查询结果， start 是起始偏移量，num  返回行数。
当不同数据类型的值进行运算或比较时，会发生隐式数据类型转换。`SELECT '1' + 1; -- 结果为 2`

# 2. 二叉树、B树、B+树

- 1.**二叉树**具有以下性质：左子树的键值小于根的键值，右子树的键值大于根的键值。下图线性二叉树的查询效率就低。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821154010052-779184076.png)

- 2.**平衡二叉树（AVL树）**在符合二叉查找树的条件下，还满足任何节点的两个子树的高度最大差为1。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821154037213-1789401676.png)

- 3.**平衡多路查找树（B-Tree）**，m个子节点。节点包含数据，单条数据查询效率更高。MongoDB在大多数情况下，只需要查询单条数据索引，使用B树。

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821154057316-1843035106.png)

**缺点**：每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。B树没有解决元素遍历的效率低下的问题，不支持范围查询。

- 4.**B+Tree**的高度一般都在2~4层。mysql的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。**B+树的非叶子节点只存储键值，不存储数据，而叶子节点存储了所有的数据，并且构成了一个双向有序链表。减少了查询时的磁盘I/O次数，也支持范围查询。**

![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821154117840-1597722525.png)



# 3. B+ 树能存放多少条数据？为啥inno DB单表记录推荐2000万行

InnoDB存储引擎中有页（Page）的概念，页是其磁盘管理的最小单位，默认16K。InnoDB每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小16KB。内存和磁盘的页大小是4KB。

- 总记录数为 = **根节点指针数\*单个叶子节点记录行数 **。
- 比如聚集索引，主键ID为bigInt 长度为8 字节，innoDB 源码设置为6字节，一条记录就是14字节。一页能放 16*1024÷14 = 1170
- 假如每条数据大小为1K, 一页能存放16k/1k = 16.
- 高度为3层的能放 1170\*1170\* 16 = 219002400，大概2200万左右。主键索引最多查询3次，非主键索引要查6(3+3)次。
- 如果是 非聚集索引，叶子结点存放的是聚集索引(主键Id)，则能存放的数量更大。


# 4. Mysql 日志文件介绍

（1）通过数据库锁的机制，保障事务的**隔离性**；
（2）通过 Redo Log（重做日志）来，保障事务的**持久性**；
（3）通过 Undo Log （撤销日志）来，保障事务的**原子性**；
（4）通过 Undo Log （撤销日志）来，保障事务的**一致性**；

- 慢查询日志（slow query log）:记录慢查询的日志文件
- 查询日志（general log）:记录所有对数据库请求的信息
- 重做日志（redo log）: 记录更新的值，事务提交后生效。固定大写、循环写。以物理方式记录了对数据库页的更改。
- 回滚日志（undo log）: 记录原来的值，事务回滚时，用于恢复原来的值。主要用于事务的回滚与MVCC。
- 二进制日志（binlog）:用于数据库备份、主从复制，从库利用主库上的binlog进行重播，实现主从同步。追加写默认100MB，超过会创建新的文件。记录的是逻辑SQL语句。
    - 通过sync_binlog控制二进制日志同步磁盘信息：为0时，mysql不做控制，依赖Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘；为n时，代表n次事务提交之后进行强制刷盘。
- 错误日志（errorlog）: 记录 MySQL 服务器启动、关闭及运行错误等信息
- 中继日志（relay log）: 主从复制中，备库将主库的二进制日志复制到自己的中继日志中，从而在本地进行重放

![](https://img2024.cnblogs.com/blog/1694759/202405/1694759-20240511180514254-1344438541.png)




# 5. MySQL中MyISAM 与Innodb的区别

- 索引上的区别：
    + InnoDB主键索引是聚簇索引；MyISAM索引是非聚簇索引，索引和数据分开存储。
    + InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
    + MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。
    + InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。
    + InnoDB支持MVCC、外键；Myisam不支持外键,支持全文索引。
- 表/行锁差异: InnoDB支持事物、支持行级锁(基于索引来完成行锁)，Myisam支持表级锁,不支持事物。
- 表主键：MyISAM允许没有主键与索引。InnoDB如果没设置主键或者非空索引,就会自动生成一个6字节的主键(用户不可见)
- 行数统计count：没有where的count()使用MyISAM要比InnoDB快得多。因为MyISAM内置了一个计数器，count()时它直接从计数器中读，而InnoDB必须扫描全表。

# 6. Innodb引擎四大特点

- **插入缓冲（insert buffer)**：先将数据插入或更新 写到Buffer Pool 缓冲池,然后再按一定频率一起写到硬盘，目的 减少IO带来的损耗。
- **二次写(double write)**：位于系统表空间的存储区域，用来缓存InnoDB的数据页从innodb buffer pool中flush之后并写入到数据文件之前。
- **自适应哈希索引(ahi)**：某二级索引被频繁访问、减少B+树查询次数(2-4次)，系统自动建立哈希索引，加快查询速度。
- **预读(read ahead)** : 如果一个w磁盘区(extent)中的被顺序读取的page超过或者等于该参数变量时，Innodb将会异步的将下一个extent读取到buffer pool中


# 7. count 字段区别

- 1.count(可空字段) 扫描全表，读到server层，判断字段可空，拿出该字段所有值，判断每一个值是否为空，不为空则累加
- 2.count(非空字段)与count(主键 id) 扫描全表，读到server层，判断字段不可空，按行累加。
- 3.count(1) 扫描全表，但不取值，server层收到的每一行都是1，判断不可能是null，按值累加。注意：count(1)执行速度比count(主键 id)快的原因：从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。
- 4.count(*)在优化器做了专门优化,返回的行一定不是空。扫描全表，但是不取值，按行累加。


# 10. drop、delete 与 truncate 的区别？

三者都表示删除，但是三者有一些差别：

| 区别     | delete                                   | truncate                       | drop                                               |
| -------- | ---------------------------------------- | ------------------------------ | -------------------------------------------------- |
| 类型     | 属于 DML                                 | 属于 DDL                       | 属于 DDL                                           |
| 回滚     | 可回滚                                   | 不可回滚                       | 不可回滚                                           |
| 删除内容 | 表结构还在，删除表的全部或者一部分数据行 | 表结构还在，删除表中的所有数据 | 从数据库中删除表，所有数据行，索引和权限也会被删除 |
| 删除速度 | 删除速度慢，需要逐行删除                 | 删除速度快                     | 删除速度最快                                       |

因此，在不再需要一张表的时候，用 drop；在想删除部分数据行时候，用 delete；在保留表而删除所有数据的时候用 truncate。



# 11. MySQL 常用函数

`CONCAT()`: 连接两个或多个字符串。
`LENGTH()`: 返回字符串的长度。
`SUBSTRING()`: 从字符串中提取子字符串。
`REPLACE()`: 替换字符串中的某部分。
`DATE_ADD()` 和 `DATE_SUB()`: 在日期上加上或减去指定的时间间隔。
`DATEDIFF()`: 返回两个日期之间的天数。
`NOW()`: 返回当前的日期和时间。
`SUM()`: 计算数值列的总和。
`AVG()`: 计算数值列的平均值。
`COUNT()`: 计算某列的行数。
`MAX()` 和 `MIN()`: 分别返回列中的最大值和最小值。
`GROUP_CONCAT()`: 将多个行值连接为一个字符串。
`IF()`: 如果条件为真，则返回一个值；否则返回另一个值。
`CASE`: 根据一系列条件返回值。

# 12. 聚集索引与非聚集索引

- 聚集索引： 数据行的物理顺序与列值（一般是主键的那一列）的逻辑顺序相同，一个表中只能拥有一个聚集索引,一般指主键。
- 非聚集索引：除聚集索引外其他都是的，包括普通索引，唯一索引，全文索引。叶子节点并不包含行记录的全部数据.
- 使用非聚集索引查询，而查询列中包含了其他该索引没有覆盖的列，那么他还要进行第二次的查询，查询节点上对应的数据行的数据。

# 20. 创建索引的原则

- 1.较为频繁查询条件的字段；
- 2.字段区分度、离散值较高的；
- 3.索引字段长度不能太长；
- 4.索引的个数不要太多，能复用组合索引尽量复用；
- 5.索引列尽量指定为NOT NULL；
- 6.频繁更新的列不适合索引；




# 21. 慢SQL优化思路

- **慢查询日志记录慢SQL**
- **explain查询分析SQL的执行计划**

    - **type**表示连接类型，查看索引执行情况的一个重要指标。以下性能从好到坏依次：system  > const > eq_ref > ref  > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL
        - system：这种类型要求数据库表中只有一条数据，是const类型的一个特例，一般情况下是不会出现的。
        - const：通过一次索引就能找到数据，一般用于主键或唯一索引作为条件，这类扫描效率极高，，速度非常快。
        - eq_ref：常用于主键或唯一索引扫描，一般指使用主键的关联查询
        - ref : 常用于非主键和唯一索引扫描。
        - ref_or_null：这种连接类型类似于ref，区别在于MySQL会额外搜索包含NULL值的行
        - index_merge：使用了索引合并优化方法，查询使用了两个以上的索引。
        - unique_subquery：类似于eq_ref，条件用了in子查询
        - index_subquery：区别于unique_subquery，用于非唯一索引，可以返回重复值。
        - range：常用于范围查询，比如：between ... and 或 In 等操作
        - index：全索引扫描
        - ALL：全表扫描
    - possible_keys: 可能使用的索引，表示查询可能使用的索引列表。
    - rows: 估计的行数，表示查询扫描的行数估计值。
    - **extra** 该字段包含有关MySQL如何解析查询的其他信息，它一般会出现这几个值
        - Using filesort：表示按文件排序，一般是在指定的排序和索引排序不一致的情况才会出现。一般见于order by语句
        - Using index ：表示是否用了覆盖索引。
        - Using temporary: 表示是否使用了临时表,性能特别差，需要重点优化。一般多见于group by语句，或者union语句。
        - Using where : 表示使用了where条件过滤.
        - Using index condition：MySQL5.6之后新增的索引下推。在存储引擎层进行数据过滤，而不是在服务层过滤，利用索引现有的数据减少回表的数据

- **慢查询SQL注意事项**
    - 隐式转换
    - 最左匹配
    - 深分页问题
    - in元素过多:建议不要超过 200个
    - order by 走文件排序导致的慢查询
    - 索引字段上使用（!=、 not in、is null、is not null），索引可能失效
    - 左右连接，关联的字段编码格式不一样
    - delete + in子查询(大量数据) 可能会扫描全表，不走索引
    - 深分页查询时，利用索引字段子查询方式提升性能.总数量count问题无法解决

```
    SELECT * FROM product WHERE ID > =(select id from product limit 866613, 1) limit 20
```

## Explain执行计划存在的坑

- limit在explain时无效,会忽略limit
- explain预估影响行数的机制,会根据索引前8页与最后一页估算数据平均值,可能会和实际行数差距较大,analyze table 解决.
- 使用索引后、数据扫描过多,可能依然全表扫描,如果SQL查询中涉及相关索引字段的强类型转换,也会全表扫描
- 如果觉得explain不太准，可以使用 show session status like "Handler%"； show profile 这两个命令对SQL进行更准确的分析。

# 22. SQL调优方案

- 数据库配置调优: 增加硬件资源、根据场景设置数据库引擎、调整缓冲池(高并发频繁更新时禁用查询缓存)提高读取性能、设置事务隔离级别(高并发场景RC级别)
- 索引优化: 控制索引长度、索引列的分散度、索引的数量、复合索引、索引类型
- 覆盖索引: 减少不需要的字段返回，减少回表查询
- 索引下推: 可以在索引层面进行部分条件的过滤，减少回表操作，提高查询效率。UNION ALL 代替 UNION。
- 排序优化: 减少不必要的排序，部分排序使索引失效，利用索引的有序性进行排序。
- 子查询优化: 执行子查询时，MYSQL需要创建临时表，查询完毕后再删除这些临时表，根据情况改用join方式(不要超过3张表，小表驱动大表方式处理) 或 大表场景推荐应用层merge数据.
- SQL语句优化: 分页查询limit场景,越往后越慢(使用上一页索引条件替代：id> xx); 报表类多表关联改成ES或者宽表实现；避免不需要的列，不要select *。
- 索引字段失效场景：避免使用 != 或者 <> 操作符；避免列上使用函数；

## 索引失效

- 1、查询时索引列不能为null值，因为索引是有序的，建索引时无法确定位置。
- 2、查询时 采用is Null,只能全表扫描。
- 3、数据库数据量较少时，mysql判断全表查询快时将不使用索引。
- 4、like查询以%开头(通配符在最前面)，索引列类型隐士转换、列参与函数运算、使用or查询，联合索引非最左
- 5、数据分布不均匀、使用不等号条件


# 23. 索引下推ICP

- Mysql 5.6及之后，index filter和table filter进行分离。index filter在引擎层进行过滤，**减少存储引擎回表查询的数据开销**。
- 就是将原本需要在**Server层**对数据进行过滤的条件下推到了**引擎层**去做，在引擎层过滤更多的数据，这样从引擎层发送到Server层的数据就会显著减少，从而优化性能。
- 在 InnoDB 中.ICP 的目的就是为了减少回表导致的磁盘 I/O，
    - index key ：确定SQL查询在索引中的连续范围(起始范围+结束范围),扫描的索引数据范围。
    - index filter ：根据 index key的索引范围 根据where条件进一步使用索引进行过滤。
    - table filter：where条件中不能使用索引的， 只能 回表查询进行条件过滤。
- 不支持聚簇索引、子查询条件的下推、存储过程条件、触发器条件的下推

> 示例：
> 当查询条件包含多个字段，且其中一部分字段可以利用索引进行筛选时，索引下推可以减少不必要的全表扫描或索引回表操作。
> 例如，查询语句SELECT * FROM users WHERE age > 18 AND city = 'Beijing'中，
> 如果age和city字段上建立了复合索引，ICP可以先在索引中筛选出满足age > 18的记录，再进一步筛选出city = 'Beijing'的记录，减少不必要的数据加载。

# 24. MySQL的MRR多范围读取优化

MRR（Multi-Range Read optimization）多范围读取优化。是 InnoDB 存储引擎为了提高 **范围查询（如 BETWEEN, IN 等）**的性能而引入的一种优化技术。
在没有 MRR 之前，InnoDB 对于范围查询可能会执行大量的随机 I/O 操作，因为每次读取一个记录后，可能需要跳转到磁盘上的另一个位置来读取下一个记录。这种随机 I/O 会严重影响性能，尤其是在机械硬盘上。
MRR 的工作原理是：

- 预读：当执行一个范围查询时，InnoDB 会首先读取所有需要的索引条目，并将它们按照主键顺序排序。
- 顺序读取：然后，InnoDB 会按照主键顺序读取所需的行数据。因为数据在磁盘上是按主键顺序存储的，所以这种读取是顺序的，而不是随机的，从而大大提高了 I/O 效率。

# 30.Mysql锁分类

![](https://img2024.cnblogs.com/blog/1694759/202406/1694759-20240628173243967-1766608892.png)

* Record Lock（记录锁）：锁住某一行记录
* Gap Lock（间隙锁）：锁住一段**左开右开** 的区间.(10,20)
* Next-key Lock（临键锁）：锁住一段**左开右闭** 的区间。等于 Gap Lock间隙锁+Record Lock记录锁。(10,20]



# 32. 多版本并发控制(MVCC)

保存数据的历史版本，通过对数据行的多个版本管理来实现数据库的并发控制,通过MVCC可以解决以下几个问题:

- 1.**并发读写之间阻塞的问题，提升事务并发处理能力**。
- 2.降低死锁的概率。MVCC采用了**乐观锁**的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。
- 3.解决一致性读的问题。一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。

## MVCC的实现原理

- MVCC 多版本并发控制,对于innodb存储引擎，每条行记录都包含两个隐藏列 db_trx_id事务Id、db_roll_ptr回滚指针。
  -- trx_id 当前修改的事务id
  -- roll_pointer 每次对某条聚集索引记录进行改动时，都会把旧版本写入undo日志中。这个隐藏列就相当于一个指针，通过它找到该记录修改前的信息。
  -- 通过 ReadView+ UndoLog 实现的，UndoLog保存了历史快照，所有的版本都会被db_roll_ptr属性形成**版本链** ，版本链的头节点就是当前记录最新的值，每个版本中还包含生成该版本时对应的事务ID(db_trx_id)。ReadView 规则帮助判断当前版本的数据是否可见。

- **快照读**：不加锁的简单 Select 都属于快照读。
- **当前读**：就是读的是最新数据,而不是历史的数据，加锁的 SELECT，或者对数据进行增删改都会进行当前读。

- Read View 保存了当前事务开启时所有活跃的事务列表。可以理解为: Read View 保存了不应该让这个事务看到的其他事务 ID 列表。
    - m_ids 系统当前正在活跃的事务ID集合。
    - min_trx_id  活跃的事务中最小的事务 ID。
    - creator_trx_id，创建这个 ReadView 的事务ID。
    - max_trx_id ,生成ReadView时系统中应该分配给下一个事务的id值。

- Read View 查询数据：
    - 获取事务自己的版本号，即 事务ID
    - 获取 Read View
    - 查询得到的数据，然后 Read View 中的事务版本号进行比较。
    - 如果不符合 ReadView 规则， 那么就需要 UndoLog 中历史快照；
    - 最后返回符合规则的数据

- Read View 规则：
  -- 如果被访问版本的 db_trx_id 值等于ReadView中的 creator_trx_id 值，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
  -- 如果被访问版本的 db_trx_id 值小于ReadView中的 min_trx_id 值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。
  -- 如果被访问版本的 db_trx_id 值大于或等于ReadView中的 max_trx_id 值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。
  -- 如果被访问版本的 db_trx_id 值在ReadView的 min_trx_id 和 max_trx_id 之间， db_trx_id 属性值是不是在 m_ids 列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。
  -- 如果某个版本的数据对当前事务不可见，就顺着版本链找到上一个版本的数据，继续按照上边的步骤依次判断可见性，直到版本链中最早的版本。如果最早的版本也不可见，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。

![MVCC数据可见性算法判断流程图](https://segmentfault.com/img/remote/1460000041553225)

![版本链结构](https://segmentfault.com/img/remote/1460000041553224)

## ReadView 中**读已提交**与**可重复读**隔离级别的区别

- **读已提交**  每次读取数据前都生成一个 ReadView。
- **可重复读**  只在第一次读取数据时生成一个 ReadView。

# 33. 可重复读什么场景下还会产生幻读

可重复读（RepeatableRead）通过多版本并发控制（MVCC）机制在很大程度上避免了不可重复读的问题，但在特定场景下，幻读仍然可能发生。幻读通常指的是在一个事务范围内，两次执行相同的范围查询时，第二次查询返回了第一次查询时不存在的新行，主要原因是**其他事务中插入的**。产生幻读的典型场景包括：

- 事务开始前，普通select是不加锁（select..for update）, 即MVCC机制的快照读。因为没有相关临建锁（next-key lock），其他事物在此期间插入数据。然后在执行当前读的时候，就会发现两次查询的记录条目不一样了，这也就产生了幻读。
- 如果事务上来就加锁执行（select..for update），此种会进行加锁，影响其他事物的并行读写。

从MySQL 5.5版本开始，InnoDB引入了可重复读隔离级别下的幻读预防机制，即所谓的Next-Key Locks，这在一定程度上减少了幻读的发生。Next-Key Lock实际上是一个行锁加上前驱间隙锁的组合，它能阻止在已锁定的区间内插入新的记录，从而在很多情况下避免了幻读。
然而，这种机制并不能完全消除所有幻读的可能性，特别是在**不涉及唯一索引的范围查询**中，或者当新插入的记录恰好填补了两个现有记录之间的间隙时，幻读仍然可能出现。

# 34. Innodb的事务与隔离级别

- 隔离级别：读未提交(RU)、读已提交(RC)、可重复读(RR)、Serializable串行化，mysql默认可重复读RR，Oracle默认采用RC。mysql通过MVCC(多版本控制)和 Next-key lock(间隙锁)解决了幻读。
- **MVCC是解决读写并行的幻读，而next-key lock 间隙锁 是解决写写并行的幻读**。
- 间隙锁（Next-Key锁）:防止幻读,当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；
  对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。在Read Committed及RU隔离级别下，不会使用间隙锁。
- RR隔离级别**没有完全解决幻读问题**,同一个事务里面通过当前读(select for update之类、update、insert、delete)或者多个事务先更新然后快照读的形式来获取数据，就会产生幻读。
- RR快照读只会读取当前事务下数据的“历史态”，但当更新(dml、ddl）时，事务会去查看“当前态”某些数据行，验证数据的可执行性（如主键冲突、唯一性约束冲突等等）。一但有“当前态”的行数据被更新，这个行就会和当前”历史态“数据合并成新的”历史态“，此后该事务的快照读均是读取的新”历史态“快照。
- 当前读：对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式。在执行这几个操作时会读取最新的版本号记录，写操作后把版本号改为了当前事务的版本号，所以即使是别的事务提交的数据也可以查询到。
  假设要update一条记录，但是在另一个事务中已经delete掉这条数据并且commit了，如果update就会产生冲突，所以在update的时候需要知道最新的数据。也正是因为这样所以才导致幻读。

- 幻读：指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。

- **如何解决幻读？**
    - 在快照读情况下,mysql通过mvcc来避免幻读。
    - 在当前读情况下通过X锁或Next-key来避免其他事物修改;
        - 使用串行化隔离级别
        - (update、delete)当where条件作为主键时,通过对主键索引加record locks来处理幻读。
        - (update、delete)当where条件为非主键索引时，通过next-key锁处理。next-key是record locks(索引加锁/行锁) 和 gap locks(间隙锁，每次锁住的不光是需要使用的数据，还会锁住这些数据附近的数据)的结合。

- MVCC 和 Next-Key Locks 能有效减轻幻读问题，但无法在所有情况下完全解决幻读。在某些特定情况下，如涉及范围查询，仍然可能发生幻读。
  比如： 假设有两个事务，事务1和事务2。事务1首先开启事务并查询某些数据，此时只有两行记录。在T3时刻，事务2插入一条数据并立即提交。在T4时刻，事务1再次查询数据时，仍然只能看到T2时刻的数据，这是符合可重复读的。然而，在T5时刻，事务1尝试更新一条不存在的数据，却意外地执行成功了。在T6时刻，事务1再次查询数据时，却发现多了一条记录，这就是幻读的现象。

| 事务隔离级别 | 脏读 | 不可重复读 | 幻读 |
| :----------: | :--: | :--------: | :--: |
|  读未提交RU  |  是  |     是     |  是  |
|  读已提交RC  |  否  |     是     |  是  |
|  可重复读RR  |  否  |     否     |  是  |
|    串行化    |  否  |     否     |  否  |

- RC级别没有间隙锁，通过where条件过滤后，不符合条件的记录的行锁会释放掉。RC的并发性能高于RR。RC允许不可重复读和幻读的。



# 35. Innodb引擎为何 double write files 双写缓冲文件？

- MySQL中一页数据是16kb，操作系统一个页是 4kb，所以刷到磁盘，要写4个文件系统里的页。刷页时并非原子操作,可能会造成「Partial Page Write（部分页写入）」;双写缓冲区由 128 个页（Page）组成，每个页通常是 16KB，因此总大小为 128 * 16KB = 2MB。磁盘上：这部分位于系统表空间的两个连续扩展（extend1 和 extend2），也是 128 个页，同样总计 2MB。
    - 顺序快速：这部分位于磁盘上系统表空间的两个连续扩展（extend1 和 extend2），也是 128 个页，同样总计 2MB。
    - 离散写入：InnoDB会将这些页分别写入到各自对应的数据文件（表空间文件）中，因为每个页可能属于不同的表或索引，因此它们可能分布在不同的位置。

- 通过双写机制，将数据写入到磁盘的两个不同位置，来避免由于磁盘损坏等因素导致数据丢失或不一致的问题。**保证MySQL数据的可靠性和一致性**
- 在系统恢复期间，InnoDB会检查共享表空间中双写缓冲区的副本(double write buffer)，并尝试从中恢复损坏的数据页。如果double write buffer中的数据是完整的，那么InnoDB就会用它数据来更新损坏的页。如果double write buffer中的数据不完整，InnoDB也有可能丢弃buffer内容，重新执行那条redo log以尝试恢复数据。

![](https://img-blog.csdnimg.cn/29cbdc9584af4279a89436948e26b4e4.png)

- 每个InnoDB表都会对应一个或多个**.ibd文件**，其中包含表的数据（包括表的行数据）和索引信息（包括表的主键索引和辅助索引），还包含MVCC相关数据

## 可以不写双缓冲文件么？

- redo日志是无法修复 部分页写入问题,redo log的内容包括 存储表空间ID、页号、偏移量和需要更新的值,记录的是逻辑变更而不是物理页面的完整状态，部分写入的数据页可能无法正确解析。
- 恢复成本: 仅依赖Redo Log恢复数据页需要更多的计算和时间成本




# 36. 如果脏页没有刷回，数据库宕机了怎么办？修改不就丢失了吗？

- 事务未提交，MySQL宕机，这种情况， Buffer Pool中的数据丢失，并且 redo log buffer中的日志也会丢失，不影响数据。
- 事务提交后，我们可以设置参数***innodb_flush_log_at_trx_commit***来决定redo log 的刷盘策略(设置为 1)：
    - 0 提交事务时，不会将redo log buffer中的数据写入os buffer，而是每秒写入os buffer并刷到磁盘；
    - 1 (默认)提交事务时，必须把redo log从内存刷入到磁盘文件中；
    - 2 提交事务时，将redo log写入os buffer中，默认每隔1s将os buffer中的数据刷入磁盘。


# 42. 一条查询MySQL的执行过程

![](https://img2024.cnblogs.com/blog/1694759/202407/1694759-20240725165306875-52043749.png)

![](https://img2024.cnblogs.com/blog/1694759/202407/1694759-20240725162257723-256191357.png)

- 连接器: 数据库身份验证、权限验证、连接参数配置
- 查询缓存: 检查缓存中是否有,如果有直接返回。
- 解析器和预处理器: 对查询语句进行语法解析(词法分析、语法分析、预处理),转换成内部数据结构。
- 优化器: 会根据查询语句的结构和表的统计信息(数据大小、索引大小)、系统配置缓存与CPU 生成多个查询计划,根据成本估算器挑出最优执行计划。
- 执行器: 根据选定的执行计划,调用存储引擎的API查询数据。
- 存储引擎: 负责实际数据的存储和检索。

![](https://img2024.cnblogs.com/blog/1694759/202402/1694759-20240207113625379-1338904182.png)


# 43. Mysql如何更新一条数据的

- 1. 解析SQL语句：MySQL服务器接收到UPDATE语句后，首先通过解析器（Parser）解析SQL语句，确保语法正确，并构建查询计划。

- 2. 查询优化：分析器后的优化器（Optimizer）根据数据库的统计信息选择最佳的执行计划，例如决定使用哪种索引来访问数据。

- 3. 获取数据：执行器（Executor）根据优化后的计划找到满足WHERE条件的行。如果id是主键，InnoDB存储引擎会使用B+树索引直接定位到行。

- 4. 锁定数据：InnoDB使用行级锁（如Record Locks）来锁定即将更新的行，以避免并发问题。如果需要，还可能使用间隙锁（Gap Locks）或Next-Key Locks 防止幻读。

- 5. 执行更新：

    - 执行器调用存储引擎接口，将新值写入内存中的缓冲池（Buffer Pool）。如果数据页不在内存中，会先从磁盘读取到缓冲池。
    - 当需要更新或者读取某条数据的时候，会把对应的页加载到内存中的 Buffer Pool 缓冲池中（默认为 128m 当然为了提高系统的并发度，你可以把这个值设置大一点）。当更新数据的时候，如果对应的页在 Buffer Pool 中，则直接更新 BP中的数据页即可，如果不在BP中，才会加载磁盘中对应的页到BP中，然后更新，此时BP中的页则跟磁盘中的页不一致，称为脏页。这些脏页是要被刷回磁盘中的。
        - ①. BP不够用了，要给新加载的页腾位置，所以会利用改进的 LRU 算法，将最近最久未使用的脏页刷回磁盘。
        - ②. 后台线程会在MySQL空闲的时候，将脏页刷回到磁盘中
        - ③. redolog写满时
        - ④. 数据库关闭时会将所有脏页刷回到磁盘中。

- 6. 双写缓冲区：修改后的数据页首先写入到双写缓冲区，然后再写入到磁盘上的系统表空间的双写区域。

- 7. Redo Log：修改操作记录在redo log中，并标记为待提交状态。如果配置了innodb_flush_log_at_trx_commit为1或2，redo log会立即写入磁盘。

- 8. 数据页更新：缓冲池中的数据页被更新，并将更新后的页写回磁盘。

- 9. Undolog操作：如果事务是可回滚的，对应的undolog信息也会被记录，以备回滚操作。

- 10. 提交事务：如果事务成功，执行器调用存储引擎接口提交事务，将redo log标记为提交状态。

- 11. Binary Log：事务提交后，binlog（二进制日志）会被写入磁盘，用于复制和恢复。

- 12. 释放锁：事务完成后，锁定的资源被释放。

![](https://img2024.cnblogs.com/blog/1694759/202407/1694759-20240725164326086-445769725.png)

![](https://img2024.cnblogs.com/blog/1694759/202402/1694759-20240206174634276-1082574582.png)

## Redolog与Binlog产生的过程

- 1.事务开始：当一个事务开始时，MySQL会记录该事务的开始信息到binlog中，这通常是BEGIN语句的记录。
- 2.事务执行：事务中的各个SQL操作在InnoDB存储引擎内部执行，此时数据变更被记录在内存中的redo log（重做日志）里，但尚未持久化到磁盘上的数据文件。
- 3.事务提交准备：当事务中的所有操作执行完毕，事务进入预提交（prepare）阶段，这时InnoDB会确保事务可以被提交，同时也会生成相应的binlog事件（但尚未实际写入到binlog文件）。这个阶段保证了事务的原子性和持久性。
- 4.写入binlog：在事务预提交之后，MySQL会将之前准备好的binlog事件正式写入到binlog文件中。这个步骤发生在事务实际提交之前，目的是为了确保即使在事务提交后、数据变更反映到数据文件之前，binlog已经包含了事务的所有更改信息。
- 5.事务提交：最后，事务被正式提交，InnoDB会将redo log从内存刷盘，并且更新事务状态，会将该事务的GTID(全局事务ID)记录到binlog中，此时客户端会收到事务成功的确认。



# 44. Redo log 是循环写的，之前的数据会不会丢失？

Redo Log是InnoDB存储引擎用于实现事务持久性和恢复的关键组件。它是循环写的，意味着当Redo Log的空间用完后，每次快写满时Checkpoints规则, 会覆盖旧的记录，但这并不会导致之前的数据丢失，原因如下：

- Checkpoints规则： InnoDB使用Checkpoints来确保数据的持久性。在每次checkpoint时，将buffer中日志页都刷到磁盘，并更新系统表空间（System Tablespace）中的redo log位置信息。这样，即使redo log被覆盖，InnoDB也可以通过checkpoint信息知道哪些数据已经安全地写入了数据文件。
- Rollback Segments： 除了Redo Log外，InnoDB还使用Rollback Segments来跟踪事务的回滚信息。这些信息在事务提交后会被清理，因此不会占用Redo Log的长期空间。
- 崩溃恢复： 在系统崩溃或异常关机后，InnoDB会在启动时执行崩溃恢复。它会从最新的checkpoint开始，应用Redo Log中的所有未提交的事务，以确保数据的一致性。已经提交的事务不会丢失，因为它们已经在checkpoint之前写入了数据文件。


# 45. Mysql集群原理及数据一致性方案

![](https://img2024.cnblogs.com/blog/1694759/202407/1694759-20240725183202347-1893340845.png)

- **异步复制**: 默认情况下执行事务操作的线程不会等复制 Binlog 的线程。

    - 在客户端向 MySQL 主库提交事务请求后，主库会先将事务记录到 Binlog，然后提交事务，更新存储引擎的数据，事务提交成功后，返回成功响应给客户端。**同时从库会开启一个专门的复制线程**，接收主库的 Binlog，并将其写入**中继日志**，然后向主库返回复制成功的响应。从库还有一个回放 Binlog 的线程，用于读取中继日志并回放 Binlog 以更新存储引擎的数据。
- **全同步复制**: 须收到所有从库的ack，才会提交事务。性能差，可用性也很差。

- **半同步复制**: 从 5.7 版本开始,事务线程无需等待所有复制成功响应，只需要一部分复制响应返回后，就可以向客户端反馈.

    - 在 master 更新操作写入 Binlog 后，会主动通知 slave，slave 接收到后写入 Relay Log 即可回应。master 只需收到至少一个 ACK 应答，便可提交事务。


![](https://img2020.cnblogs.com/blog/1694759/202108/1694759-20210821153204938-711203546.png)

![](https://img2024.cnblogs.com/blog/1694759/202406/1694759-20240628172610782-1568508577.png)

# 46.wms数据库在线分库扩容实现方案

- 1.确定分库中间件Mycat,分库以仓库id为分片键。
- 2.检查所有需要分库相关业务表对应的sql相关代码、业务表主键生成规则改造，join查询优化改造，并确保所有操作都带分片键。
- 3.中间件提供技术支撑：Mycat配置分片规则，并实现新老库数据双写机制；读写优先老库，并支持按仓库id分片键切换，分库写入失败进行告警。
- 4.测试环境数据验证、按门店灰度验证，告警根因分析与修复，每天定时任务新老数据CRC验证。
- 5.线上分库历史数据按照分片键迁移到分库，同时业务代码上线。
- 6.线上每天定时任务新老数据验证，数据无差异后，并开启部分门店生产灰度读写走分库。
- 7.经过一段时间，线上全部切换分库方案，中间件配置老库读写关闭。待老库完全没有流量后，下线老库。

# 47.千万级大表如何添加字段

常用方案 ：**中间表转换**
- 1.创建一个原表的临时表结构；
- 2.给临时表添加新的字段与索引；
- 3.把旧表数据复制过去。
- 4.然后通过一个rename操作 把临时表改名成原表、原表改成备份表。`RENAME TABLE old_table TO old_table_backup, new_table TO old_table;`
- 5.通过drop删除备份表。

rename过程中：1.如果业务先有锁，先等业务操作完成后释放相关表锁，rename才开始执行。2.rename执行时，也是先加表锁，此瞬间业务流程被夯住，等执行完成后，释放锁，业务流程正常执行。rename操作很快。



# 48.Mysql数据库CPU飙升如何处理

- 确认突然是否有大量的 session 连进来导致 cpu 飙升，kill掉一些不必要的或者空闲的连接。然后去分析为何连接数会激增原因，再做出相应的调整，比如说限制连接数、使用连接池等。
- 查看当前MySQL服务器上的所有活动会话，特别关注那些运行时间长、状态为“Query”的会话，先进行kill掉这些线程。分析慢查询日志，然后对这些慢sql语句进行分析与优化，是否未命中索引，是否查询数据量太多等。
- 如果服务器的硬件资源（如CPU、内存）不足以支持当前的连接数与数据性能，考虑升级硬件。

# 50. LSM树(Log Structured Merge Trees)原理

- 将对数据的修改增量保存在内存中，达到指定大小限制之后批量把数据flush到磁盘中，磁盘中树定期可以做merge操作，合并成一棵大树，以优化读性能。不过读取的时候稍微麻烦一些，读取时看这些数据在内存中，如果未能命中内存，则需要访问较多的磁盘文件。
- LSM牺牲了部分读性能，提高写性能。适用于写多读少的场景。主要劣势：读写放大（磁盘上实际读写的数据量 / 用户需要的数据量）。
- LSM是当前被用在许多产品的文件结构策略：HBase,TIDB,mangoDb 等。
- LSM树的核心特点是利用顺序写来提高写性能，但因为分层(此处分层是指的分为内存和文件两部分)的设计会稍微降低读性能，但是通过牺牲小部分读性能换来高性能写，使得LSM树成为非常流行的存储结构。

![](https://img2020.cnblogs.com/blog/1694759/202111/1694759-20211119204033094-907558566.png)

![](https://img2020.cnblogs.com/blog/1694759/202111/1694759-20211119205246316-371070524.png)

![](https://img2020.cnblogs.com/blog/1694759/202111/1694759-20211119205331509-1561924404.png)


# 60. ShardingSphere参考文档

    Alpha 指的是内测、Beta 指的是公测、RC 正式发布的候选版本
    ShardingSphere 可插拔架构,已实现数据分片、读写分离、数据加密、影子库、数据库发现等功能。

```
    https://blog.csdn.net/xinzhifu1/article/details/109309303  分片策略 学习
    https://blog.csdn.net/dhaibo1986/article/details/120397730  对接中存在的一些坑
    https://shardingsphere.apache.org/document/5.0.0-RC1/cn/user-manual/shardingsphere-jdbc/configuration/java-api/sharding/  官方文档
```


# 61. 分库分表规则

## 1.分库的策略：
- 垂直分库：按照业务模块将不同的表拆分到不同的库中。
- 水平分库：按照一定的策略将一个表中的数据拆分到多个库中。

## 2.分表的策略：
- **配置路由方式**: 通过配置表来确定数据存储的表，适用于分片键不规律的场景。
- **数值Range分表**:按商户Id区间分表
    - 优点：单表大小可控;扩容方便,无需对其他分片数据迁移；可快速进行范围查询，避免分片问题。
    - 缺点：热点数据成为性能瓶颈
- **Hash取模分表**：按商户Id取模
    - 优点：数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈。
    - 缺点：后期扩容时，需要迁移旧的数据很难；跨分片查询复杂,需要在内存中合并数据返给应用。
- **一致性Hash算法分表**
    - 优点具有Hash取模分表的优点,可以很好解决扩容问题，也会存在迁移旧的数据的难题。

## 3.分库分表举例方案
- 比如订单表t_order,id生成规则 将商户id后4位，用户id后4位，记录到订单号后面。 C端用户按照 用户表后4位进行分库分表。然后通过bin-log消息将订单数据再同步到商家库里面。这样可以解决站在用户和商家维度分页排序聚合等查询。
- 库名定义：用户ID % 32 取余数,假如用户Id后4位为1026, 1026%32 = 2,也就是说这个数据在 DB2 数据库里面。
- 表名定义: (用户ID/32)%32 取余数，假如用户Id后4位为1026,  1026/32 =32, 32%32 =0, 这个数据在 t_order0 里面。

优点：可以查询指定用户（商户）的所有订单，可以避免跨库跨表查询。
缺点：若是部分用户单了特别多，可能会部分表数据量特别大。


# 62. 分库分表常见中间件

|            |  MyCat  | Sharding-JDBC |
| ---------- | :-----: | :-----------: |
| 分库       |   有    |      有       |
| 分表       |   无    |      有       |
| 中间层     |   有    |      无       |
| ORM支持    |  任意   |     任意      |
| 数据库支持 | 仅MySQL |     任意      |

- **MyCat** 基于阿里的cobar基础二次开发。只支持分库,中间层代理,后端SQL查询运维也很方便。

  ![](https://img2022.cnblogs.com/blog/1694759/202204/1694759-20220427101004320-86053275.png)

  支持前端作为MySQL通用代理
  基于心跳的自动故障切换，支持读写分离
  支持数据的多片自动路由与聚合
  支持sum,count,max等常用的聚合函数,支持跨库分页
  支持弱XA,XA分布式事务
  支持非堆内存\(Direct Memory\)聚合计算

  Mycat-server-1.6-RELEASE.jar

## Mycat注意事项

- 1.跨分片Join：mycat 目前只支持两张分片表的 Join，如果要支持多张表需要自己改造程序代码或者改造Mycat的源代码。
- 2.子查询结果可能不正确；
- 3.非分片键 查询时,会查询所有分库，然后Mycat服务端聚合数据。
- 4.非分片键分页查询时，会扫描所有库且查询最大量，然后Mycat服务端聚合数据，很容易OOM；
- 5.复杂的SQL语法不支持，比如：复制插入、复杂更新；
- 6.偶发Count查询时，返回异常（有数据，返回Null）；

# 63. Sharding-JDBC 内置分片算法与主键生成策略

InlineShardingAlgorithm	    基于行表达式的分片算法
ModShardingAlgorithm	    基于取模的分片算法
HashModShardingAlgorithm	基于哈希取模的分片算法
VolumeBasedRangeShardingAlgorithm	基于分片容量的范围分片算法
BoundaryBasedRangeShardingAlgorithm	基于分片边界的范围分片算法
ComplexKeysShardingAlgorithm  复合(多分片建)分片算法

## 主键生成策略
UUID生成策略、雪花生成策略、基于 KeyGenerateAlgorithm 自定义策略
ShardingJdbc的雪花算法强依赖时间、时钟回拨，会产生重复的ID。


# 64. sharding-JDBC分页排序问题

- **排序**：然后将查询结果放各自队列，各队列再进行比较，再排序，类似流的方式比较，时间复杂度O(n).

> 举例 sql是 select * from user order by id desc;
> 假如两个表 ，sql将被改写成：
>  select * from user_0 order by id desc;
>  select * from user_1 order by id desc;

- **分页**：采用流式处理 + 归并排序的方式来避免内存的过量占用,**将全量数据查出来进行分页**，时间复杂度O(n).

> 举例SQL分页 select * from user u limit100000,10;
> sharding-jdbc的sql路由改写成如下sql：
> select * from user_0 u limit 0,100010;
> select * from user_1 u limit 0,100010;
> 然后查出结果再在归并器里处理，这样的性能很难让人接受

- 解决方案：避免无唯一分片键的排序与分页查询SQL;

> 采用ES查询,把常用搜索条件与排序字段都索引进去。这样先查询ES,返回分片策略id。然后再拿id去各个表中查询。

# 65.分布式Id生成方案

- 雪花算法：单机序列号递增,每毫米可以4百万的订单Id。缺点:严重依赖系统时钟，如果时钟回拨，会生成重复的ID。是一个64位的整数,最大值为2的64次方,为19位的数字。
    - 符号位（1 位）：用于表示正负号。
    - 时间戳部分（41 位）：通常是当前时间戳减去一个固定的起始时间戳得到的值。
    - 机器 ID 部分（10 位）：用来标识生成 ID 的机器的唯一标识。
    - 序列号部分（12 位）：用来标识同一毫秒内生成的不同 ID。

![](https://img2020.cnblogs.com/blog/1694759/202112/1694759-20211221181638790-264722255.png)

![](https://img2024.cnblogs.com/blog/1694759/202402/1694759-20240226182306591-1609094823.png)

>  * 阉割版雪花算法：SnowFlake的结构如下(每部分用-分开):
>  * 0000000000 0000000000 0000000 - 000000000 - 00000000
>  * 27位时间截(毫秒级)，时间截的差值（当前时间截 - 当前时间零点时间截)
>  * 9位的数据机器位，可以部署在512个节点
>  * 8位序列，毫秒内的计数，256位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生256个ID序号
>  * 加起来刚好44位，为一个11位数16进制数  （后期如果不能接受字母，或者位数过长，建议接入自增id生成器,但是生成时间是该生成器的10倍+）



- 美团Leaf为了解决时钟回拨，引入了zookeeper(leaf服务与ZK时间定时比较,如有时差告警)。
- 也可以使用雪花算法+号段模式。如：百度的UidGenerator、滴滴的TinyId。

