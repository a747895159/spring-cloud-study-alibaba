
https://www.cnblogs.com/crazymakercircle/p/14731826.html


# 1.分布式缓存 Redis与DB数据一致性解决方案

- 缓存是通过牺牲强一致性来提高性能的,由CAP理论决定的。缓存系统适用的场景就是非强一致性的场景，它属于CAP中的AP。
- 双删机制: 先删缓存、**更新数据库、再删缓存**
- Canal+RocketMQ同步MySQL，由消息统一进行删除缓存。


# 2.Redisson锁简介
- Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。
- RLock结构 key就是UUID+threadId，hash结构的value就是重入值，在分布式锁时，这个值为1（Redisson还可以实现重入锁，那么这个值就取决于重入次数了）


# 3.Redis中hash表扩容原理,与HashMap 的区别？
- 从数据结构的角度来看，redis的dict和java的HashMap很像，区别在于rehash：HashMap在resize时是一次性拷贝的，然后使用新的数组，而dict维持了2个dictht，平常使用ht[0]，一旦开始rehash则使用ht[0]和ht[1]，rehash被分摊到每次的dictAdd和dictFind等操作中。

- 当hash内部的元素比较拥挤时(hash碰撞比较频繁)，就需要进行扩容。扩容需要申请新的两倍大小的数组，然后将所有的键值对重新分配到新的数组下标对应的链表中(rehash)。如果hash结构很大，比如有上百万个键值对，那么一次完整rehash的过程就会耗时很长。这对于单线程的Redis里来说有点压力山大。所以Redis采用了渐进式rehash的方案。它会同时保留两个新旧hash结构，在后续的定时任务以及hash结构的读写指令中将旧结构的元素逐渐迁移到新的结构中。这样就可以避免因扩容导致的线程卡顿现象。

- ht是一个数组，有且只有俩元素ht[0]和ht[1];其中，ht[0]存放的是redis中使用的哈希表，而ht[1]和rehashidx和哈希表的 rehash有关。ht[0]，是存放数据的table，作为非扩容时容器。ht[1]，只有正在进行扩容时才会使用，它也是存放数据的table，长度为ht[0]的两倍。
扩容时，单线程A负责把数据从ht[0] copy到ht[1] 中。如果这时有其他线程
进行读操作：会先去ht[0]中找，找不到再去ht[1]中找。
进行写操作：直接写在ht[1]中。

- 不同的是，Redis的字典只能是字符串，另外他们rehash的方式不一样，因为Java的HashMap的字典很大时，rehash是个耗时的操作，需要一次全部rehash。Redis为了追求高性能，不能堵塞服务，所以采用了渐进式rehash策略。渐进式rehash会在rehash的同时，保留新旧两个hash结构，查询时会同时查询两个hash结构，然后在后续的定时任务以及hash操作指令中，循环渐进地将旧hash的内容一点点地迁到新的hash结构中。当搬迁完成了，就会使用新的hash结构取而代之。当hash移除最后一个元素后，该数据结构自动删除，内存被回收。

- hash结构也可以用来存储用户信息，与字符串需要一次性全部序列化整个对象不同，hash可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时，可以进行部分获取。而以整个字符串的形式去保存用户信息的话，就只能一次性全部读取，这样就会浪费网络流量。但是hash结构的存储消耗要高于单个字符串。

- **两者对比**： 1.扩容所花费的时间对比： 一个单线程渐进扩容，一个多线程协同扩容。在平均的情况下，是ConcurrentHashMap 快。这也意味着，扩容时所需要 花费的空间能够更快的进行释放。 2.读操作，两者性能相差不多。 3.写操作，Redis的字典返回更快些，因为它不像ConcurrentHashMap那样去帮着扩容(当要写的桶位已经搬到了newTable时)，等扩容完才能进行操作。 4.删除操作，与写一样。



# 4.如何解决缓存热点（热key）问题？

- 本地缓存caffeine + 分布式缓存redis.以下是多级缓存注解事项：

	- 两级缓存数据一致性问题？
		+ 后台保存数据后，写入Redis缓存，同时发布MQ消息。业务应用接收到消息后删除本地缓存。
		+ 当流量请求到达时，业务应用若本地缓存不存在，则从 Redis 中加载缓存至本地缓存。
	- 本地缓存要解决JVM内存问题，不适合存储大量数据,需要对缓存大小进行评估。
	- 本地缓存数据应设置效期和合理的淘汰策略,建议使用caffeine,策略是LRU+LFU，既具有较好的时间局部性，又具有大部分数据场景。
	
	```
	Cache<String, Map<Integer, String>> cache = Caffeine.newBuilder().expireAfterWrite(5, TimeUnit.MINUTES).maximumSize(500).build()
	
	```
    - 考虑设置定时任务来同步缓存，以防止极端情况下数据丢失。
    - 当应用重启时，本地缓存会失效，因此需要注意加载分布式缓存的时机。
    - 当本地缓存失效时，需要使用 synchronized 进行加锁，确保由一个线程加载 Redis 缓存，避免并发更新。
    - 如果业务能够接受短时间内的数据不一致，那么本地缓存更适用于读取场景。
    

# 5.Redis集群用的是什么方式，怎么做动态扩容?

Redis集群中每个redis实例（可能一台机部署多个实例）会使用两个Tcp端口，一个用于给客户端（redis-cli或应用程序等）使用的端口 6379，另一个是用于集群中实例相互通信的内部总线端口，且第二个端口比第一个端口一定大10000。
Redis Cluster使用Gossip协议维护节点的元数据信息，这种协议是P2P模式的，主要指责就是信息交换
Gossip协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，这种方式类似流言传播。是一种去中心化思路的分布式协议，来确保网络中所有节点的数据一样。

Redis 集群使用的方式是主从复制，其中一个主节点负责写入数据，从节点负责备份数据。
迁移过程中，主节点会将部分槽和数据复制到新的从节点上，直到新节点上的数据与主节点上的数据一致。此时，新节点就可以加入到 Redis 集群中，开始提供读写服务。
保证集群在运行过程中不停机，并且能够快速响应节点故障和负载增加的情况。


# 6.关于 redis，说一下 sorted set 底层原理

Redis 的 sorted set 是一种有序集合，它的底层实现是使用了 **跳跃表（Skip List）和哈希表（Hash Table）** 这两种数据结构。跳跃表是一种类似于链表的数据结构，但是它在每个节点上增加了多个指针，可以快速地跳过一些节点，从而提高了查找效率。而哈希表则是一种以键值对形式存储数据的数据结构，可以快速地进行数据的插入、查找和删除操作。
在 Redis 的 sorted set 中，每个元素都有一个分数（score），根据分数的大小来进行排序。使用跳跃表可以快速地进行分数的比较和排序，而使用哈希表可以快速地进行元素的查找和删除操作。同时，Redis 还使用了压缩列表（Ziplist）来优化存储空间，对于一些小的 sorted set，它们的元素可以被存储在一个压缩列表中，从而减少了内存的使用。

sorted set 底层的原理如下：
- **哈希表** ：每个 sorted set 对象都由一个哈希表和一个分数(score)组成。哈希表用于存储成员的分值和成员的散列值(member),分数用于对成员进行排序。
- **分数计算** ：sorted set 中的每个成员都有一个分数，该分数是根据其散列值和一个权重因子计算出来的。权重因子是一个介于 0 到 100 之间的整数，用于调整不同成员的分值大小。
- **成员添加和删除** ：当向 sorted set 中添加或删除成员时，Redis 首先会根据其散列值计算出新的分数，然后将新分数与旧分数进行比较，如果新分数大于旧分数，则更新哈希表中的对应项。
- **范围查询** ：sorted set 支持范围查询，即可以根据分数范围查找成员。当执行范围查询时，Redis 首先会计算出最小分值和最大分值之间的所有成员的分数范围，然后遍历哈希表，找到所有分数在该范围内的成员。
- **迭代器** ：sorted set 支持迭代器，可以通过迭代器遍历 sorted set 中的所有成员。迭代器返回每个成员的散列值和分值，但不返回成员本身。

总之，sorted set 底层的原理是基于哈希表和分数计算实现的，它支持添加、删除、范围查询和迭代等操作。由于 sorted set 可以快速地进行范围查询和排序操作，因此在实际应用中被广泛使用。


# 7.说一下 mongoDB

MongoDB是一种NoSQL数据库，它采用文档存储方式，支持动态查询和索引。下面是MongoDB的特性、优缺点和应用。

特性：

- **支持动态查询和索引** ：MongoDB使用BSON（Binary JSON）格式存储数据，支持动态查询和索引，可以快速查询和分析数据。
- **支持复制和故障转移** ：MongoDB支持复制和故障转移，可以保证数据的高可用性和可靠性。
- **支持分片** ：MongoDB支持自动分片，可以扩展到大规模数据集。
- **支持MapReduce** ：MongoDB支持MapReduce，可以进行复杂的数据分析和聚合。
- **支持全文搜索** ：MongoDB支持全文搜索，可以对文本进行高效的搜索和分析。

优点：

- **高性能** ：MongoDB采用内存映射和预分配空间等技术，可以实现高性能的读写操作。
- **易于扩展** ：MongoDB支持自动分片和复制，可以方便地进行扩展。
- **灵活性** ：MongoDB采用文档存储方式，可以方便地存储结构不固定的数据。
- **易于使用** ：MongoDB使用简单，支持多种编程语言和平台。

缺点：

- **不支持事务** ：MongoDB不支持多文档事务，只支持单文档事务。
- **存储空间占用较大** ：MongoDB采用BSON格式存储数据，存储空间占用较大。
- **不支持复杂查询** ：MongoDB不支持复杂查询，如多表连接等。

应用：

- **Web应用** ：MongoDB可以用于Web应用的数据存储和查询。
- **大数据分析** ：MongoDB支持MapReduce，可以用于大数据分析。
- **日志处理** ：MongoDB可以用于日志处理和分析。
- **移动应用** ：MongoDB可以用于移动应用的数据存储和查询。

# 8.分布式限流网关组件

**使用Redis+Lua来开发**,无论是Nginx外部网关还是Zuul内部网关，都可以使用Redis+Lua限流组件.理论上，接入层的限流有多个维度：
（1）用户维度限流：在某一时间段内只允许用户提交一次请求，比如可以采取客户端IP或者用户ID作为限流的key。
（2）商品维度的限流：对于同一个抢购商品，在某个时间段内只允许一定数量的请求进入，可以采取秒杀商品ID作为限流的key。

什么时候用nginx限流：
	用户维度的限流，可以在ngix 上进行，因为使用nginx限流内存来存储用户id，比用redis 的key，来存储用户id，效率高。
什么时候用redis+lua分布式限流：
	商品维度的限流，可以在redis上进行，不需要大量的计算访问次数的key，另外，可以控制所有的接入层节点的访问秒杀请求的总量。

# 9.redis三大客户端选型

- **Jedis客户端**：提供了比较全面的Redis命令的支持。
	- 缺点：阻塞的I/O，不支持异步；客户端实例线程不安全，需要通过连接池来使用。
	
- **Lettuce客户端**：可扩展的线程安全的Redis客户端，支持异步IO。基于Netty框架实现。支持高级Redis特性，如集群、Sentinel、管道和编码器的支持。**Spring Boot2.0 默认使用的Redis客户端是Lettuce**。
	
- **Redisson客户端**：是一个在 Redis 的基础上实现的 Java 驻内存数据网格。线程安全的客户端，基于Netty的非阻塞I/O，性能较高。提供很多分布式相关操作服务，例如，分布式锁，分布式集合，可通过Redis支持延迟队列。
	- 缺点：Redisson 对字符串的操作支持比较差；不支持排序、事务、管道、分区等Redis特性。

**使用建议：lettuce + Redisson**


# 10.什么是BigKey

* 【字符串类型】： 单个 string 类型的 value 值超过 1MB，就可以认为是 Bigkey。
* 【非字符串类型】：哈希、列表、集合、有序集合等， 它们的元素个数超过 2000 个，就可以认为是 Bigkey。

存在问题：
- **侵占带宽网络拥堵**
- **数据请求大量超时**: redis是单线程的，当一个key数据响应的久一点，就会造成后续请求频繁超时
- **内存溢出或处理阻塞**：可以过大时会导致内存数据溢出；同时过期删除时，由于数据量过大，会影响主从同步。

解决方案： 将BigKey进行业务拆分，分成多个小key。



# 11.什么是HotKey

某个key频繁被访问，访问次数显著高于其他key，单点访问频率过高，占用大量资源。

存在问题：
- **分片服务瘫痪**: 同一个实例下某个key访问量很高，占用某个分片大量资源，而其他分片访问较少。

- **cpu占用高，影响其他服务**: 单个分片cpu占用率过高，其他分片无法拥有cpu资源，从而被影响

- **引发缓存击穿**: 当缓存请求不到会去请求数据库。如果请求过于集中，redis承载不了，就会有大量请求打到数据库。**此时，可能引发数据库服务瘫痪。进而引发系统雪崩** 。

解决方案： 使用本地缓存


# 12.主从复制的核心原理

- 1 当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。

- 2 如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。

>
> 此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。
>
> RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，
>
> 会先写入本地磁盘，然后再从本地磁盘加载到内存中，
>

- 3 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段master 将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。

- 4 部分复制。如果slave node跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。

![](https://img-blog.csdnimg.cn/20210612182456981.png)


# 12.Redis为啥设计成16384个槽

16384=16k，在发送心跳包时使用char进行bitmap压缩后是2k（2 * 8 (8 bit) * 1024(1k) = 16K）个char，也就是说使用2k个char的空间，能表达16k的槽数。
虽然使用CRC16算法最多可以分配65535（2^16-1）个槽位，65535=65k，压缩后就是8k（8 * 8 (8 bit) * 1024(1k) =65K），也就是说需要需要8k的心跳包，作者认为这样做不太值得。
集群节点越多，心跳包的消息体内携带的数据越多，如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。


# 12.Redis脑裂问题

Redis脑裂是指在一个Redis集群中，由于某些原因（如网络问题、配置错误等），导致集群中的多个节点无法相互通信，进而造成数据不一致和丢失的现象。脑裂现象对于Redis集群的稳定性和数据完整性构成了严重威胁。

脑裂问题的发生通常涉及以下几个方面：

- 网络问题：在网络不稳定或者分区的情况下，Redis集群中的节点之间可能无法正常通信，从而导致脑裂现象。
- 配置错误：如果Redis集群的配置不当，比如节点间的超时时间设置不合理，或者节点数量过多导致通信压力增大，都可能增加脑裂发生的风险。
- 主从切换问题：在Redis的主从复制架构中，如果主节点宕机，从节点需要通过选举来升级为新的主节点。在这个过程中，如果旧的主节点重新上线并且继续处理写请求，就会与新的主节点形成两个主节点并存的局面，导致脑裂。









