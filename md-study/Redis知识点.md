
https://www.cnblogs.com/crazymakercircle/p/14731826.html


# 1.分布式缓存 Redis与DB数据一致性解决方案

- 缓存是通过牺牲强一致性来提高性能的,由CAP理论决定的。缓存系统适用的场景就是非强一致性的场景，它属于CAP中的AP。
- 双删机制: 先删缓存、**更新数据库、再删缓存**
- Canal+RocketMQ同步MySQL，由消息统一进行删除缓存。


# Redisson锁简介
- Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。
- RLock结构 key就是UUID+threadId，hash结构的value就是重入值，在分布式锁时，这个值为1（Redisson还可以实现重入锁，那么这个值就取决于重入次数了）


# Redis中hash表扩容原理,与HashMap 的区别？
- 从数据结构的角度来看，redis的dict和java的HashMap很像，区别在于rehash：HashMap在resize时是一次性拷贝的，然后使用新的数组，而dict维持了2个dictht，平常使用ht[0]，一旦开始rehash则使用ht[0]和ht[1]，rehash被分摊到每次的dictAdd和dictFind等操作中。

- 当hash内部的元素比较拥挤时(hash碰撞比较频繁)，就需要进行扩容。扩容需要申请新的两倍大小的数组，然后将所有的键值对重新分配到新的数组下标对应的链表中(rehash)。如果hash结构很大，比如有上百万个键值对，那么一次完整rehash的过程就会耗时很长。这对于单线程的Redis里来说有点压力山大。所以Redis采用了渐进式rehash的方案。它会同时保留两个新旧hash结构，在后续的定时任务以及hash结构的读写指令中将旧结构的元素逐渐迁移到新的结构中。这样就可以避免因扩容导致的线程卡顿现象。

- ht是一个数组，有且只有俩元素ht[0]和ht[1];其中，ht[0]存放的是redis中使用的哈希表，而ht[1]和rehashidx和哈希表的 rehash有关。ht[0]，是存放数据的table，作为非扩容时容器。ht[1]，只有正在进行扩容时才会使用，它也是存放数据的table，长度为ht[0]的两倍。
扩容时，单线程A负责把数据从ht[0] copy到ht[1] 中。如果这时有其他线程
进行读操作：会先去ht[0]中找，找不到再去ht[1]中找。
进行写操作：直接写在ht[1]中。

- 不同的是，Redis的字典只能是字符串，另外他们rehash的方式不一样，因为Java的HashMap的字典很大时，rehash是个耗时的操作，需要一次全部rehash。Redis为了追求高性能，不能堵塞服务，所以采用了渐进式rehash策略。渐进式rehash会在rehash的同时，保留新旧两个hash结构，查询时会同时查询两个hash结构，然后在后续的定时任务以及hash操作指令中，循环渐进地将旧hash的内容一点点地迁到新的hash结构中。当搬迁完成了，就会使用新的hash结构取而代之。当hash移除最后一个元素后，该数据结构自动删除，内存被回收。

- hash结构也可以用来存储用户信息，与字符串需要一次性全部序列化整个对象不同，hash可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时，可以进行部分获取。而以整个字符串的形式去保存用户信息的话，就只能一次性全部读取，这样就会浪费网络流量。但是hash结构的存储消耗要高于单个字符串。

- **两者对比**： 1.扩容所花费的时间对比： 一个单线程渐进扩容，一个多线程协同扩容。在平均的情况下，是ConcurrentHashMap 快。这也意味着，扩容时所需要 花费的空间能够更快的进行释放。 2.读操作，两者性能相差不多。 3.写操作，Redis的字典返回更快些，因为它不像ConcurrentHashMap那样去帮着扩容(当要写的桶位已经搬到了newTable时)，等扩容完才能进行操作。 4.删除操作，与写一样。



#2. 如何解决缓存热点（热key）问题？

- 本地缓存caffeine + 分布式缓存redis.以下是多级缓存注解事项：

	- 两级缓存数据一致性问题？
		+ 后台保存数据后，写入Redis缓存，同时发布MQ消息。业务应用接收到消息后删除本地缓存。
		+ 当流量请求到达时，业务应用若本地缓存不存在，则从 Redis 中加载缓存至本地缓存。
	- 本地缓存要解决JVM内存问题，不适合存储大量数据,需要对缓存大小进行评估。
	- 本地缓存数据应设置效期和合理的淘汰策略,建议使用caffeine,策略是LRU+LFU，既具有较好的时间局部性，又具有大部分数据场景。
	
	```
	Cache<String, Map<Integer, String>> cache = Caffeine.newBuilder().expireAfterWrite(5, TimeUnit.MINUTES).maximumSize(500).build()
	
	```
    - 考虑设置定时任务来同步缓存，以防止极端情况下数据丢失。
    - 当应用重启时，本地缓存会失效，因此需要注意加载分布式缓存的时机。
    - 当本地缓存失效时，需要使用 synchronized 进行加锁，确保由一个线程加载 Redis 缓存，避免并发更新。
    - 如果业务能够接受短时间内的数据不一致，那么本地缓存更适用于读取场景。
    

#3. Redis集群用的是什么方式，怎么做动态扩容?

Redis 集群使用的方式是主从复制，其中一个主节点负责写入数据，从节点负责备份数据。
迁移过程中，主节点会将部分槽和数据复制到新的从节点上，直到新节点上的数据与主节点上的数据一致。此时，新节点就可以加入到 Redis 集群中，开始提供读写服务。
保证集群在运行过程中不停机，并且能够快速响应节点故障和负载增加的情况。


#4. 关于 redis，说一下 sorted set 底层原理

Redis 的 sorted set 是一种有序集合，它的底层实现是使用了 **跳跃表（Skip List）和哈希表（Hash Table）** 这两种数据结构。跳跃表是一种类似于链表的数据结构，但是它在每个节点上增加了多个指针，可以快速地跳过一些节点，从而提高了查找效率。而哈希表则是一种以键值对形式存储数据的数据结构，可以快速地进行数据的插入、查找和删除操作。
在 Redis 的 sorted set 中，每个元素都有一个分数（score），根据分数的大小来进行排序。使用跳跃表可以快速地进行分数的比较和排序，而使用哈希表可以快速地进行元素的查找和删除操作。同时，Redis 还使用了压缩列表（Ziplist）来优化存储空间，对于一些小的 sorted set，它们的元素可以被存储在一个压缩列表中，从而减少了内存的使用。

sorted set 底层的原理如下：
- **哈希表** ：每个 sorted set 对象都由一个哈希表和一个分数(score)组成。哈希表用于存储成员的分值和成员的散列值(member),分数用于对成员进行排序。
- **分数计算** ：sorted set 中的每个成员都有一个分数，该分数是根据其散列值和一个权重因子计算出来的。权重因子是一个介于 0 到 100 之间的整数，用于调整不同成员的分值大小。
- **成员添加和删除** ：当向 sorted set 中添加或删除成员时，Redis 首先会根据其散列值计算出新的分数，然后将新分数与旧分数进行比较，如果新分数大于旧分数，则更新哈希表中的对应项。
- **范围查询** ：sorted set 支持范围查询，即可以根据分数范围查找成员。当执行范围查询时，Redis 首先会计算出最小分值和最大分值之间的所有成员的分数范围，然后遍历哈希表，找到所有分数在该范围内的成员。
- **迭代器** ：sorted set 支持迭代器，可以通过迭代器遍历 sorted set 中的所有成员。迭代器返回每个成员的散列值和分值，但不返回成员本身。

总之，sorted set 底层的原理是基于哈希表和分数计算实现的，它支持添加、删除、范围查询和迭代等操作。由于 sorted set 可以快速地进行范围查询和排序操作，因此在实际应用中被广泛使用。


###5. 说一下 mongoDB

MongoDB是一种NoSQL数据库，它采用文档存储方式，支持动态查询和索引。下面是MongoDB的特性、优缺点和应用。

特性：

- **支持动态查询和索引** ：MongoDB使用BSON（Binary JSON）格式存储数据，支持动态查询和索引，可以快速查询和分析数据。
- **支持复制和故障转移** ：MongoDB支持复制和故障转移，可以保证数据的高可用性和可靠性。
- **支持分片** ：MongoDB支持自动分片，可以扩展到大规模数据集。
- **支持MapReduce** ：MongoDB支持MapReduce，可以进行复杂的数据分析和聚合。
- **支持全文搜索** ：MongoDB支持全文搜索，可以对文本进行高效的搜索和分析。

优点：

- **高性能** ：MongoDB采用内存映射和预分配空间等技术，可以实现高性能的读写操作。
- **易于扩展** ：MongoDB支持自动分片和复制，可以方便地进行扩展。
- **灵活性** ：MongoDB采用文档存储方式，可以方便地存储结构不固定的数据。
- **易于使用** ：MongoDB使用简单，支持多种编程语言和平台。

缺点：

- **不支持事务** ：MongoDB不支持多文档事务，只支持单文档事务。
- **存储空间占用较大** ：MongoDB采用BSON格式存储数据，存储空间占用较大。
- **不支持复杂查询** ：MongoDB不支持复杂查询，如多表连接等。

应用：

- **Web应用** ：MongoDB可以用于Web应用的数据存储和查询。
- **大数据分析** ：MongoDB支持MapReduce，可以用于大数据分析。
- **日志处理** ：MongoDB可以用于日志处理和分析。
- **移动应用** ：MongoDB可以用于移动应用的数据存储和查询。